{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2b1e034",
   "metadata": {},
   "source": [
    "# Future:\n",
    "Try implementing a dual memory. one with regular game states and the other with death states so that it can be somewhat ephasized during training and when the bot succeeds at beating the game it will still remember the game over moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f29438-c5f9-4040-86e0-3a470086ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "from jupyterplot import ProgressPlot\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "989d967b-11c9-4f49-868b-85bba02426fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mem:\n",
    "    def __init__(self, cap):\n",
    "        self.que = deque([], maxlen=cap)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.que)\n",
    "    \n",
    "    def sample(self, bs):\n",
    "        return random.sample(self.que, bs)\n",
    "    \n",
    "    def push(self, data):\n",
    "        self.que.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d163b650-2c4a-464e-8414-b6ce4d7dd83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action(state, eps):\n",
    "    if random.random() < eps: #pick random action\n",
    "        return torch.randint(0,2,(), device=device)\n",
    "        return torch.randperm(2, device=device)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            a = torch.argmax(pol(state).squeeze())\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1038ee1d-9496-40db-af8b-fa981ec81c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Qnet, self).__init__()\n",
    "        self.flat = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(4, 10)\n",
    "        self.linear3 = nn.Linear(10, 10)\n",
    "        self.linear4 = nn.Linear(10, 2)\n",
    "        self.act = nn.Mish()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.act(x)\n",
    "        x = self.linear4(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "pol = Qnet().to(device)\n",
    "target = Qnet().to(device)\n",
    "target.load_state_dict(pol.state_dict())\n",
    "target.eval()\n",
    "\n",
    "optimizer = torch.optim.Adam(pol.parameters())\n",
    "loss = nn.SmoothL1Loss()\n",
    "#loss = nn.MSELoss()\n",
    "\n",
    "mem = Mem(int(1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27026259-37cc-4a00-bdfa-46e88a35fef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "env.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc8f8eb2-22be-402b-a9d5-454ee3137ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10000\n",
    "EPS_MIN = 0.05\n",
    "EPS_MAX = 0.95\n",
    "EPS_MOMENT = 0.9\n",
    "EPS_DEC = 200\n",
    "GAMMA = 0.999\n",
    "BS = 512\n",
    "TARGET_UPDATE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e6ab236-4398-4ca4-8fae-d67786958b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt():\n",
    "    if len(mem) < BS:\n",
    "        return False\n",
    "    pol.train()\n",
    "    \n",
    "    #transpose\n",
    "    data = list(zip(*mem.sample(BS)))\n",
    "\n",
    "    s = torch.cat(data[0])\n",
    "    a = torch.stack(data[1])\n",
    "    ns = torch.cat(data[2])\n",
    "    r = torch.stack(data[3])\n",
    "\n",
    "    q = pol(s).gather(1, a.view(-1,1))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        qg = torch.zeros((len(r), 1), device=device)\n",
    "        mask = r != 0\n",
    "        qg[mask] = GAMMA * target(ns[mask]).max(1, keepdim=True)[0] + r[mask].reshape((-1,1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    l = loss(q, qg)\n",
    "    l.backward()\n",
    "    for param in pol.parameters():\n",
    "        param.grad.data.clamp_(-1,1)\n",
    "    optimizer.step()\n",
    "\n",
    "    return l.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25459f1f-8a93-461f-ae5f-dc1eb88e888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = ProgressPlot(line_names=['duration'])\n",
    "#ppr = ProgressPlot(line_names=['rewards'])\n",
    "\n",
    "ema = 0\n",
    "for i in range(EPOCHS):\n",
    "    env.render()\n",
    "    pol.eval()\n",
    "    state = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float, device=device).unsqueeze(0)\n",
    "    c = 0\n",
    "    tr = 0\n",
    "    best = 0\n",
    "    avgloss = 0\n",
    "    losscount = 1\n",
    "    while True:\n",
    "        env.render()\n",
    "        c += 1\n",
    "        \n",
    "        #eps = (EPS_MAX-EPS_MIN)/(1+np.exp((-c+ema)/20)) + EPS_MIN\n",
    "        eps = EPS_MIN + (EPS_MAX - EPS_MIN) * math.exp(-1. * i / EPS_DEC)\n",
    "        a = action(state, 0.05)\n",
    "        ns, r, d, _ = env.step(a.item())\n",
    "        ns = torch.tensor(ns.copy(), dtype=torch.float, device=device).unsqueeze(0)\n",
    "                \n",
    "        tr += r\n",
    "        r = torch.tensor(r, dtype=torch.float, device=device)\n",
    "        l = opt()\n",
    "        if l:\n",
    "            avgloss = avgloss + (l-avgloss)/(losscount)\n",
    "            losscount += 1\n",
    "        if d:\n",
    "            ema = EPS_MOMENT * ema + (1-EPS_MOMENT) * c\n",
    "            mem.push((state, a, ns, torch.tensor(0, device=device)))\n",
    "            break\n",
    "        #mem.push((state, a[i], ns, r))\n",
    "        mem.push((state, a, ns, r))\n",
    "        state = ns\n",
    "    if i % TARGET_UPDATE == 0:\n",
    "        target.load_state_dict(pol.state_dict())\n",
    "    pp.update(c)\n",
    "    print(avgloss, '\\t\\t', end='\\r')\n",
    "    #ppr.update(float(best))\n",
    "pp.finalize()\n",
    "#ppr.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5c13b4",
   "metadata": {},
   "source": [
    "# If you wanan just use the pretrained models\n",
    "the file names are w.pt and winner.pt. both will achieve max scores that you can watch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a22b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pol.load_state_dict(torch.load('w.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d65019aa-eee7-4192-adf2-da403f19c2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     ns, r, d, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(a\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     11\u001b[0m     ns \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(ns\u001b[38;5;241m.\u001b[39mcopy(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     state \u001b[38;5;241m=\u001b[39m ns\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(c, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    state = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float, device=device).unsqueeze(0)\n",
    "    d = False\n",
    "    while not d:\n",
    "        env.render()\n",
    "        a = action(state, 0)\n",
    "        ns, r, d, _ = env.step(a.item())\n",
    "        ns = torch.tensor(ns.copy(), dtype=torch.float, device=device).unsqueeze(0)\n",
    "        time.sleep(1/20)\n",
    "        state = ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cf72346-9df5-42db-91c4-4eb3ba0a31a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'savefile.pt'\n",
    "torch.save(pol.state_dict(), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a588f939-9b51-47f7-8e12-07ac7153e496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
